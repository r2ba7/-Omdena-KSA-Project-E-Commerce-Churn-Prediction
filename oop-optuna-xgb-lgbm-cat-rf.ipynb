{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\nfrom sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, f1_score,roc_curve, precision_score, recall_score,roc_auc_score\nfrom sklearn import linear_model, tree, ensemble\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.simplefilter(action=\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-29T13:52:48.392493Z","iopub.execute_input":"2023-03-29T13:52:48.392871Z","iopub.status.idle":"2023-03-29T13:52:48.400003Z","shell.execute_reply.started":"2023-03-29T13:52:48.392832Z","shell.execute_reply":"2023-03-29T13:52:48.398842Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def reduce_memory_usage(df):\n    for col in df.columns:\n        col_type = df[col].dtype\n        if col_type != 'object':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    pass\n        else:\n            df[col] = df[col].astype('category')\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-03-28T23:49:48.771946Z","iopub.execute_input":"2023-03-28T23:49:48.772473Z","iopub.status.idle":"2023-03-28T23:49:48.786558Z","shell.execute_reply.started":"2023-03-28T23:49:48.772426Z","shell.execute_reply":"2023-03-28T23:49:48.784837Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"class Preprocessing:\n    def __init__(self, df):\n        self.df = df\n        \n    def shape(self):\n        print(f'shape: {self.df.shape}')\n    \n    def dtypes(self, pr=False):\n        print(\"Types\")\n        if pr:\n            print(self.df.dtypes)\n            \n    def supposed2beint(self):\n        float_cols = [column for column in self.df.columns if self.df[column].dtype == 'float']\n        int2be_cols = []\n        for col in float_cols:\n            if (self.df[col].fillna(-9999) % 1  == 0).all() == True:\n                int2be_cols.append(col)\n        return int2be_cols\n                \n    def isNaN(self, pr=False):\n        if pr:\n            print(\"Contain NaN\")\n            print(self.df.isnull().sum())\n        else:\n            return self.df.columns[self.df.isna().any()].tolist()\n    \n    def isObject(self):\n        return [column for column in self.df.columns if self.df[column].dtype == 'object']\n        \n    def check_dataframe(self):\n        self.shape()\n        self.dtypes(True)\n        self.isNaN(True)\n        \n    def fillNaN(self):\n        nan_cols = self.isNaN()\n        int2be_cols = self.supposed2beint()\n        # nan_cols == int2be_cols they are the same\n        for col in int2be_cols:\n            self.df[col].fillna(round(self.df[col].mean()), inplace=True)\n            self.df[col] = self.df[col].astype(int)\n            \n    def adjust_category_cols(self):\n        self.fillNaN()\n        #PreferredLoginDevice\n        self.df.loc[self.df[\"PreferredLoginDevice\"] == \"Mobile Phone\", \"PreferredLoginDevice\"] = \"Phone\"\n        #PreferredPaymentMode\n        self.df.loc[self.df[\"PreferredPaymentMode\"] == \"Credit Card\", \"PreferredPaymentMode\"] = \"CC\"\n        self.df.loc[self.df[\"PreferredPaymentMode\"] == \"Cash on Delivery\", \"PreferredPaymentMode\"] = \"COD\"\n        #PreferredLoginDevice\n        self.df.loc[self.df[\"PreferredLoginDevice\"] == \"Mobile Phone\", \"PreferredLoginDevice\"] = \"Phone\"\n        \n    def drop_useless_cols(self):\n        self.df.drop(['CustomerID'], axis=1, inplace=True)\n        \n    def split_target(self):\n        self.adjust_category_cols()\n        self.drop_useless_cols()\n        self.X = self.df.drop('Churn', axis=1)\n        self.y = self.df['Churn'].astype(int).to_numpy()\n        \n    def find_enc_method(self):\n        cat_cols = self.isObject()\n        one_hot_cols = [col for col in cat_cols if self.X[col].nunique() <=3]\n        label_enc_cols = [col for col in cat_cols if col not in one_hot_cols]\n        return one_hot_cols, label_enc_cols, cat_cols\n    \n    def encoding(self):\n        one_hot_cols, label_enc_cols, cat_cols = self.find_enc_method()\n        num_cols = [col for col in self.X.columns if col not in cat_cols]\n        X_OHE, X_LE, X_NUM = self.X[one_hot_cols].copy(), self.X[label_enc_cols].copy(), self.X[num_cols].copy()\n        self.OHE = OneHotEncoder(drop='first', handle_unknown='error')\n        X_OHE = self.OHE.fit_transform(X_OHE).toarray()\n        self.le_dict = {}\n        self.LE = LabelEncoder()\n#         X_LE[label_enc_cols] = X_LE[label_enc_cols].apply(lambda col: self.LE.fit_transform(col))   \n        for col in X_LE.columns:\n            self.le_dict[col] = self.LE.fit(X_LE[col])\n            X_LE[col] = self.le_dict[col].transform(X_LE[col])\n        return X_OHE, X_LE.to_numpy(), X_NUM.to_numpy()\n\n    def scaling(self):\n        X_OHE, X_LE, X_num = self.encoding()\n        self.SS = StandardScaler()\n        X_num = self.SS.fit_transform(X_num)\n        self.X_total = np.concatenate((X_OHE, X_LE, X_num), axis=1)\n#         self.X_total = self.SS.fit_transform(self.X_total)\n        \n    def get_encoders(self):\n        return self.OHE, self.LE, self.le_dict\n    \n    def get_scaler(self):\n        return self.SS   \n\n    def get_default_Xy(self):\n        self.split_target()\n        return self.X, self.y\n      \n    def get_Xy(self):\n        self.split_target()\n        self.scaling()\n        return self.X_total, self.y\n\ndf = pd.read_excel('/kaggle/input/ecommerce-customer-churn-analysis-and-prediction/E Commerce Dataset.xlsx', sheet_name='E Comm')\ndata = pd.read_excel('/kaggle/input/ecommerce-customer-churn-analysis-and-prediction/E Commerce Dataset.xlsx', sheet_name='Data Dict')\npre = Preprocessing(df)\nX, y = pre.get_Xy()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T14:22:58.323905Z","iopub.execute_input":"2023-03-29T14:22:58.324300Z","iopub.status.idle":"2023-03-29T14:22:59.939746Z","shell.execute_reply.started":"2023-03-29T14:22:58.324272Z","shell.execute_reply":"2023-03-29T14:22:59.938753Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)\nmodel = linear_model.LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nCR = classification_report(y_test, y_pred)\nCM = confusion_matrix(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, y_pred)\nprint(\"=\"*60)\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(\"=\"*60)\nprint(f\"Classification Report:\\n {CR}\")\nprint(\"=\"*60)\nprint(f\"Confusion Matrix: {CM}\")\nprint(\"=\"*60)\nprint(f\"F1 Score: {f1:.4f}\")\nprint(\"=\"*60)\nprint(f\"ROC AUC Score: {roc_auc:.4f}\")\nprint(\"=\"*60)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T15:05:50.812790Z","iopub.execute_input":"2023-03-29T15:05:50.813107Z","iopub.status.idle":"2023-03-29T15:05:50.930184Z","shell.execute_reply.started":"2023-03-29T15:05:50.813081Z","shell.execute_reply":"2023-03-29T15:05:50.928537Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"============================================================\nAccuracy: 0.8757\n============================================================\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.90      0.96      0.93       936\n           1       0.70      0.46      0.55       190\n\n    accuracy                           0.88      1126\n   macro avg       0.80      0.71      0.74      1126\nweighted avg       0.86      0.88      0.86      1126\n\n============================================================\nConfusion Matrix: [[899  37]\n [103  87]]\n============================================================\nF1 Score: 0.5541\n============================================================\nROC AUC Score: 0.7092\n============================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import optuna\nfrom xgboost import XGBClassifier\ndef objective_xgb(trial):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n    param = {\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]),\n        'n_estimators': trial.suggest_categorical(\"n_estimators\", [150, 200, 300, 3000]),\n        'max_depth': trial.suggest_categorical('max_depth', [4,5,7,9,11,13,15,17]),\n        'random_state': 42,\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n    }\n    model = XGBClassifier(**param)\n    model.fit(X_train, y_train, early_stopping_rounds=50, eval_set=[(X_test, y_test)], verbose=False)   \n    preds = model.predict(X_test)\n    \n    acc = accuracy_score(y_test, preds)      \n\n    return acc\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective_xgb, n_trials=50)\nparams_xgb = study.best_trial.params\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', params_xgb)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T14:32:06.319860Z","iopub.execute_input":"2023-03-29T14:32:06.320200Z","iopub.status.idle":"2023-03-29T14:41:54.352348Z","shell.execute_reply.started":"2023-03-29T14:32:06.320172Z","shell.execute_reply":"2023-03-29T14:41:54.351654Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-03-29 14:32:06,327]\u001b[0m A new study created in memory with name: no-name-8c0fbc04-a5c0-4841-b0c3-fd4a937ea880\u001b[0m\n\u001b[32m[I 2023-03-29 14:32:07,212]\u001b[0m Trial 0 finished with value: 0.837181764357608 and parameters: {'lambda': 0.03124640759785608, 'alpha': 0.0024235868387922437, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 150, 'max_depth': 5, 'min_child_weight': 279}. Best is trial 0 with value: 0.837181764357608.\u001b[0m\n\u001b[32m[I 2023-03-29 14:32:08,434]\u001b[0m Trial 1 finished with value: 0.837181764357608 and parameters: {'lambda': 0.02321929076288543, 'alpha': 0.007059116293567424, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.012, 'n_estimators': 200, 'max_depth': 5, 'min_child_weight': 189}. Best is trial 0 with value: 0.837181764357608.\u001b[0m\n\u001b[32m[I 2023-03-29 14:32:09,371]\u001b[0m Trial 2 finished with value: 0.84251036116045 and parameters: {'lambda': 0.20396806019603347, 'alpha': 0.0015175872497201436, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.016, 'n_estimators': 150, 'max_depth': 7, 'min_child_weight': 182}. Best is trial 2 with value: 0.84251036116045.\u001b[0m\n\u001b[32m[I 2023-03-29 14:32:10,393]\u001b[0m Trial 3 finished with value: 0.8875074008288928 and parameters: {'lambda': 0.8687638316834165, 'alpha': 0.06288546253014533, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 150, 'max_depth': 9, 'min_child_weight': 51}. Best is trial 3 with value: 0.8875074008288928.\u001b[0m\n\u001b[32m[I 2023-03-29 14:32:12,203]\u001b[0m Trial 4 finished with value: 0.8709295441089402 and parameters: {'lambda': 0.00345743860099777, 'alpha': 0.01322943905591891, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.01, 'n_estimators': 300, 'max_depth': 17, 'min_child_weight': 153}. Best is trial 3 with value: 0.8875074008288928.\u001b[0m\n\u001b[32m[I 2023-03-29 14:32:13,170]\u001b[0m Trial 5 finished with value: 0.8709295441089402 and parameters: {'lambda': 0.001328186311690668, 'alpha': 3.320580139972451, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.018, 'n_estimators': 150, 'max_depth': 9, 'min_child_weight': 92}. Best is trial 3 with value: 0.8875074008288928.\u001b[0m\n\u001b[32m[I 2023-03-29 14:32:34,496]\u001b[0m Trial 6 finished with value: 0.9100059206631143 and parameters: {'lambda': 0.0024812289674640553, 'alpha': 8.464748362042078, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 3000, 'max_depth': 5, 'min_child_weight': 41}. Best is trial 6 with value: 0.9100059206631143.\u001b[0m\n\u001b[32m[I 2023-03-29 14:32:35,421]\u001b[0m Trial 7 finished with value: 0.8727057430432208 and parameters: {'lambda': 0.003554148762757024, 'alpha': 0.1626143565706184, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.014, 'n_estimators': 150, 'max_depth': 15, 'min_child_weight': 116}. Best is trial 6 with value: 0.9100059206631143.\u001b[0m\n\u001b[32m[I 2023-03-29 14:32:37,365]\u001b[0m Trial 8 finished with value: 0.8709295441089402 and parameters: {'lambda': 0.0018300487410747284, 'alpha': 0.036244407311600335, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.01, 'n_estimators': 300, 'max_depth': 5, 'min_child_weight': 117}. Best is trial 6 with value: 0.9100059206631143.\u001b[0m\n\u001b[32m[I 2023-03-29 14:32:39,526]\u001b[0m Trial 9 finished with value: 0.8709295441089402 and parameters: {'lambda': 0.001446578545391146, 'alpha': 0.7276233604505649, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.009, 'n_estimators': 300, 'max_depth': 4, 'min_child_weight': 127}. Best is trial 6 with value: 0.9100059206631143.\u001b[0m\n\u001b[32m[I 2023-03-29 14:33:03,015]\u001b[0m Trial 10 finished with value: 0.9177027827116637 and parameters: {'lambda': 7.280052002274113, 'alpha': 8.558981475554095, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 18}. Best is trial 10 with value: 0.9177027827116637.\u001b[0m\n\u001b[32m[I 2023-03-29 14:33:27,506]\u001b[0m Trial 11 finished with value: 0.9295441089402013 and parameters: {'lambda': 9.343424352567194, 'alpha': 7.299839668382715, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 2}. Best is trial 11 with value: 0.9295441089402013.\u001b[0m\n\u001b[32m[I 2023-03-29 14:33:51,318]\u001b[0m Trial 12 finished with value: 0.9218472468916519 and parameters: {'lambda': 8.748196325518451, 'alpha': 9.747244204154502, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 5}. Best is trial 11 with value: 0.9295441089402013.\u001b[0m\n\u001b[32m[I 2023-03-29 14:34:15,061]\u001b[0m Trial 13 finished with value: 0.9425695677915926 and parameters: {'lambda': 9.332907081191511, 'alpha': 1.326557363029337, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 7}. Best is trial 13 with value: 0.9425695677915926.\u001b[0m\n\u001b[32m[I 2023-03-29 14:34:31,395]\u001b[0m Trial 14 finished with value: 0.9082297217288336 and parameters: {'lambda': 2.3179238669099176, 'alpha': 1.1616386775308707, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 70}. Best is trial 13 with value: 0.9425695677915926.\u001b[0m\n\u001b[32m[I 2023-03-29 14:34:37,310]\u001b[0m Trial 15 finished with value: 0.837181764357608 and parameters: {'lambda': 0.9833306029535408, 'alpha': 0.5902292936229673, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.008, 'n_estimators': 3000, 'max_depth': 13, 'min_child_weight': 242}. Best is trial 13 with value: 0.9425695677915926.\u001b[0m\n\u001b[32m[I 2023-03-29 14:34:38,908]\u001b[0m Trial 16 finished with value: 0.9046773238602723 and parameters: {'lambda': 8.777705099972124, 'alpha': 2.1539280845453495, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 200, 'max_depth': 11, 'min_child_weight': 6}. Best is trial 13 with value: 0.9425695677915926.\u001b[0m\n\u001b[32m[I 2023-03-29 14:34:49,528]\u001b[0m Trial 17 finished with value: 0.9076376554174067 and parameters: {'lambda': 2.5861162329817984, 'alpha': 0.2936450044462853, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 63}. Best is trial 13 with value: 0.9425695677915926.\u001b[0m\n\u001b[32m[I 2023-03-29 14:35:04,927]\u001b[0m Trial 18 finished with value: 0.9117821195973949 and parameters: {'lambda': 0.3379844943906199, 'alpha': 2.629375002614112, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.014, 'n_estimators': 3000, 'max_depth': 4, 'min_child_weight': 42}. Best is trial 13 with value: 0.9425695677915926.\u001b[0m\n\u001b[32m[I 2023-03-29 14:35:23,080]\u001b[0m Trial 19 finished with value: 0.8916518650088809 and parameters: {'lambda': 3.823719614719125, 'alpha': 0.33371853941736257, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.008, 'n_estimators': 3000, 'max_depth': 15, 'min_child_weight': 87}. Best is trial 13 with value: 0.9425695677915926.\u001b[0m\n\u001b[32m[I 2023-03-29 14:35:24,631]\u001b[0m Trial 20 finished with value: 0.8875074008288928 and parameters: {'lambda': 1.034816985840103, 'alpha': 1.3894314490075412, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.009, 'n_estimators': 200, 'max_depth': 13, 'min_child_weight': 36}. Best is trial 13 with value: 0.9425695677915926.\u001b[0m\n\u001b[32m[I 2023-03-29 14:35:46,266]\u001b[0m Trial 21 finished with value: 0.9224393132030787 and parameters: {'lambda': 9.475310106782578, 'alpha': 4.9953055822127945, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 16}. Best is trial 13 with value: 0.9425695677915926.\u001b[0m\n\u001b[32m[I 2023-03-29 14:36:10,866]\u001b[0m Trial 22 finished with value: 0.9413854351687388 and parameters: {'lambda': 4.37447351569463, 'alpha': 4.416812901085984, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 3}. Best is trial 13 with value: 0.9425695677915926.\u001b[0m\n\u001b[32m[I 2023-03-29 14:36:36,569]\u001b[0m Trial 23 finished with value: 0.9526346950858496 and parameters: {'lambda': 4.429489810896814, 'alpha': 2.8972184787579014, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 1}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:36:55,836]\u001b[0m Trial 24 finished with value: 0.9153345174659562 and parameters: {'lambda': 3.665055442951319, 'alpha': 2.86723510462804, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 3000, 'max_depth': 7, 'min_child_weight': 33}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:37:10,955]\u001b[0m Trial 25 finished with value: 0.9005328596802842 and parameters: {'lambda': 2.0387158104867016, 'alpha': 1.5346681610253472, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 17, 'min_child_weight': 80}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:37:31,211]\u001b[0m Trial 26 finished with value: 0.9212551805802249 and parameters: {'lambda': 4.273006776776147, 'alpha': 3.8364907223001543, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 27}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:37:50,033]\u001b[0m Trial 27 finished with value: 0.9159265837773831 and parameters: {'lambda': 1.4958334384509753, 'alpha': 0.8627959193853616, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 57}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:37:51,226]\u001b[0m Trial 28 finished with value: 0.8715216104203671 and parameters: {'lambda': 4.2659013989804775, 'alpha': 2.1646166608698967, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 200, 'max_depth': 11, 'min_child_weight': 102}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:37:52,934]\u001b[0m Trial 29 finished with value: 0.837181764357608 and parameters: {'lambda': 0.5226220423491461, 'alpha': 4.537065946846867, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 300, 'max_depth': 11, 'min_child_weight': 260}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:37:56,134]\u001b[0m Trial 30 finished with value: 0.837181764357608 and parameters: {'lambda': 1.5182112788045192, 'alpha': 0.5417883533721359, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 3000, 'max_depth': 15, 'min_child_weight': 297}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:38:20,005]\u001b[0m Trial 31 finished with value: 0.9330965068087625 and parameters: {'lambda': 5.0233759513587755, 'alpha': 5.5805542578033664, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 4}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:38:40,228]\u001b[0m Trial 32 finished with value: 0.9194789816459443 and parameters: {'lambda': 5.337257865231697, 'alpha': 1.439333756137508, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.012, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 26}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:39:03,626]\u001b[0m Trial 33 finished with value: 0.9336885731201895 and parameters: {'lambda': 2.884354427592959, 'alpha': 4.84187742000478, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 7, 'min_child_weight': 5}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:39:06,127]\u001b[0m Trial 34 finished with value: 0.837181764357608 and parameters: {'lambda': 2.747985663081817, 'alpha': 3.992064934996563, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 7, 'min_child_weight': 188}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:39:07,121]\u001b[0m Trial 35 finished with value: 0.8691533451746596 and parameters: {'lambda': 0.12936535476427785, 'alpha': 2.04623439330268, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.012, 'n_estimators': 150, 'max_depth': 7, 'min_child_weight': 56}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:39:08,323]\u001b[0m Trial 36 finished with value: 0.8685612788632326 and parameters: {'lambda': 1.612716892049795, 'alpha': 5.662983260689012, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 200, 'max_depth': 7, 'min_child_weight': 206}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:39:17,203]\u001b[0m Trial 37 finished with value: 0.8715216104203671 and parameters: {'lambda': 0.4733003175228422, 'alpha': 1.0947276811727222, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.008, 'n_estimators': 3000, 'max_depth': 7, 'min_child_weight': 164}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:39:18,235]\u001b[0m Trial 38 finished with value: 0.8798105387803434 and parameters: {'lambda': 5.7250346316686205, 'alpha': 3.0328623313599907, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.014, 'n_estimators': 150, 'max_depth': 9, 'min_child_weight': 48}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:39:20,205]\u001b[0m Trial 39 finished with value: 0.8857312018946122 and parameters: {'lambda': 2.9637780149683066, 'alpha': 5.849239774673044, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 300, 'max_depth': 17, 'min_child_weight': 22}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:39:22,601]\u001b[0m Trial 40 finished with value: 0.837181764357608 and parameters: {'lambda': 0.7299412087821101, 'alpha': 1.749227474920876, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 5, 'min_child_weight': 210}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:39:44,362]\u001b[0m Trial 41 finished with value: 0.92599171107164 and parameters: {'lambda': 5.726288401776315, 'alpha': 9.990892060241595, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 9, 'min_child_weight': 1}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:40:05,672]\u001b[0m Trial 42 finished with value: 0.9177027827116637 and parameters: {'lambda': 4.720874115600034, 'alpha': 5.776589037781363, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 3000, 'max_depth': 4, 'min_child_weight': 13}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:40:25,573]\u001b[0m Trial 43 finished with value: 0.9188869153345175 and parameters: {'lambda': 6.167742129778899, 'alpha': 3.158368200154705, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 11, 'min_child_weight': 37}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:40:46,041]\u001b[0m Trial 44 finished with value: 0.9224393132030787 and parameters: {'lambda': 3.0378508202965766, 'alpha': 4.05682595124226, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 3000, 'max_depth': 13, 'min_child_weight': 24}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:40:47,061]\u001b[0m Trial 45 finished with value: 0.8863232682060391 and parameters: {'lambda': 1.8861617307248304, 'alpha': 6.546534585060908, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimators': 150, 'max_depth': 11, 'min_child_weight': 72}. Best is trial 23 with value: 0.9526346950858496.\u001b[0m\n\u001b[32m[I 2023-03-29 14:41:10,519]\u001b[0m Trial 46 finished with value: 0.9532267613972765 and parameters: {'lambda': 6.863193244163752, 'alpha': 0.9369522155311274, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 3000, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 46 with value: 0.9532267613972765.\u001b[0m\n\u001b[32m[I 2023-03-29 14:41:12,652]\u001b[0m Trial 47 finished with value: 0.9088217880402605 and parameters: {'lambda': 6.39082864114315, 'alpha': 0.9365785721571388, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.016, 'n_estimators': 300, 'max_depth': 5, 'min_child_weight': 16}. Best is trial 46 with value: 0.9532267613972765.\u001b[0m\n\u001b[32m[I 2023-03-29 14:41:31,125]\u001b[0m Trial 48 finished with value: 0.9088217880402605 and parameters: {'lambda': 8.653772463316116, 'alpha': 1.8384438128585014, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 3000, 'max_depth': 5, 'min_child_weight': 54}. Best is trial 46 with value: 0.9532267613972765.\u001b[0m\n\u001b[32m[I 2023-03-29 14:41:54,335]\u001b[0m Trial 49 finished with value: 0.9514505624629959 and parameters: {'lambda': 9.578411113871596, 'alpha': 0.48999394745750824, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 3000, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 46 with value: 0.9532267613972765.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Number of finished trials: 50\nBest trial: {'lambda': 6.863193244163752, 'alpha': 0.9369522155311274, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 3000, 'max_depth': 5, 'min_child_weight': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":" X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\nmodel = XGBClassifier(**params_xgb)\nmodel.fit(X_train, y_train, early_stopping_rounds=50, eval_set=[(X_test, y_test)], verbose=False)   \ny_pred = model.predict(X_test)\nprint(f\"Accuracy: {round(accuracy_score(y_pred, y_test), 2)}\")\nprint(\"=\"*60)\nprint(f\"Recall: {round(recall_score(y_pred,y_test),2)}\")\nprint(\"=\"*60)\nprint(f\"Precision: {round(precision_score(y_pred,y_test), 2)}\")\nprint(\"=\"*60)\nprint(f\"F1: {round(f1_score(y_pred,y_test), 2)}\")\nprint(\"=\"*60)\nprint(f\"Auc: {round(roc_auc_score(y_pred,y_test), 2)}\")\nprint(\"=\"*60)\nCR = classification_report(y_test, y_pred)\nCM = confusion_matrix(y_test, y_pred)\nprint(f\"Classification Report:\\n {CR}\")\nprint(\"=\"*60)\nprint(f\"Confusion Matrix: {CM}\")\nprint(\"=\"*60)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T15:05:58.527511Z","iopub.execute_input":"2023-03-29T15:05:58.527852Z","iopub.status.idle":"2023-03-29T15:06:26.523883Z","shell.execute_reply.started":"2023-03-29T15:05:58.527824Z","shell.execute_reply":"2023-03-29T15:06:26.522446Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Accuracy: 0.96\n============================================================\nRecall: 0.92\n============================================================\nPrecision: 0.85\n============================================================\nF1: 0.88\n============================================================\nAuc: 0.94\n============================================================\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.97      0.98      0.98      1405\n           1       0.92      0.85      0.88       284\n\n    accuracy                           0.96      1689\n   macro avg       0.94      0.91      0.93      1689\nweighted avg       0.96      0.96      0.96      1689\n\n============================================================\nConfusion Matrix: [[1383   22]\n [  44  240]]\n============================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import optuna\nfrom lightgbm import LGBMClassifier\ndef objective_lgbm(trial):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n    param = {\n        'random_state': 42,\n        'n_estimators': trial.suggest_categorical(\"n_estimators\", [150, 200, 300, 3000]),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.006,0.008,0.01,0.014,0.017,0.02]),\n        'max_depth': trial.suggest_categorical('max_depth', [10,20,100]),\n        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n        'cat_smooth' : trial.suggest_int('min_data_per_groups', 1, 100)\n    }\n    model = LGBMClassifier(**param)\n    model.fit(X_train, y_train, early_stopping_rounds=100, eval_set=[(X_test, y_test)], verbose=False)    \n    preds = model.predict(X_test)\n    \n    acc = accuracy_score(y_test, preds)      \n\n    return acc\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective_lgbm, n_trials=50)\nparams_lgbm = study.best_trial.params\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', params_lgbm)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T15:06:53.970414Z","iopub.execute_input":"2023-03-29T15:06:53.970749Z","iopub.status.idle":"2023-03-29T15:28:28.461302Z","shell.execute_reply.started":"2023-03-29T15:06:53.970721Z","shell.execute_reply":"2023-03-29T15:28:28.459467Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-03-29 15:06:53,978]\u001b[0m A new study created in memory with name: no-name-bfd52714-127c-47e2-aba9-40163b07b894\u001b[0m\n\u001b[32m[I 2023-03-29 15:07:00,438]\u001b[0m Trial 0 finished with value: 0.8981645944345766 and parameters: {'n_estimators': 3000, 'reg_alpha': 8.440513826558606, 'reg_lambda': 1.243054388693692, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 10, 'num_leaves': 175, 'min_child_samples': 206, 'min_data_per_groups': 37}. Best is trial 0 with value: 0.8981645944345766.\u001b[0m\n\u001b[32m[I 2023-03-29 15:07:28,830]\u001b[0m Trial 1 finished with value: 0.9413854351687388 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.00527721749672363, 'reg_lambda': 1.0253900929023407, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 10, 'num_leaves': 813, 'min_child_samples': 133, 'min_data_per_groups': 73}. Best is trial 1 with value: 0.9413854351687388.\u001b[0m\n\u001b[32m[I 2023-03-29 15:08:10,316]\u001b[0m Trial 2 finished with value: 0.9715808170515098 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.36430996902043955, 'reg_lambda': 0.3522005197131576, 'colsample_bytree': 0.9, 'subsample': 0.4, 'learning_rate': 0.01, 'max_depth': 20, 'num_leaves': 800, 'min_child_samples': 72, 'min_data_per_groups': 47}. Best is trial 2 with value: 0.9715808170515098.\u001b[0m\n\u001b[32m[I 2023-03-29 15:08:12,150]\u001b[0m Trial 3 finished with value: 0.8845470692717584 and parameters: {'n_estimators': 300, 'reg_alpha': 0.02829168404038168, 'reg_lambda': 1.4453498463813774, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 10, 'num_leaves': 634, 'min_child_samples': 218, 'min_data_per_groups': 35}. Best is trial 2 with value: 0.9715808170515098.\u001b[0m\n\u001b[32m[I 2023-03-29 15:08:18,548]\u001b[0m Trial 4 finished with value: 0.9029011249259917 and parameters: {'n_estimators': 200, 'reg_alpha': 0.09079110075477692, 'reg_lambda': 0.002021840175552464, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.006, 'max_depth': 100, 'num_leaves': 640, 'min_child_samples': 22, 'min_data_per_groups': 62}. Best is trial 2 with value: 0.9715808170515098.\u001b[0m\n\u001b[32m[I 2023-03-29 15:08:36,190]\u001b[0m Trial 5 finished with value: 0.9194789816459443 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.9150422892246508, 'reg_lambda': 3.1054512688134865, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.006, 'max_depth': 10, 'num_leaves': 55, 'min_child_samples': 191, 'min_data_per_groups': 76}. Best is trial 2 with value: 0.9715808170515098.\u001b[0m\n\u001b[32m[I 2023-03-29 15:08:57,244]\u001b[0m Trial 6 finished with value: 0.9419775014801658 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.002157652424703734, 'reg_lambda': 0.1400184563704604, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 100, 'num_leaves': 514, 'min_child_samples': 205, 'min_data_per_groups': 89}. Best is trial 2 with value: 0.9715808170515098.\u001b[0m\n\u001b[32m[I 2023-03-29 15:08:59,955]\u001b[0m Trial 7 finished with value: 0.9182948490230906 and parameters: {'n_estimators': 200, 'reg_alpha': 0.9810971337592744, 'reg_lambda': 0.005838704936068056, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 525, 'min_child_samples': 54, 'min_data_per_groups': 6}. Best is trial 2 with value: 0.9715808170515098.\u001b[0m\n\u001b[32m[I 2023-03-29 15:09:00,989]\u001b[0m Trial 8 finished with value: 0.8537596210775606 and parameters: {'n_estimators': 150, 'reg_alpha': 0.9844807157438995, 'reg_lambda': 0.0027085527443214408, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 20, 'num_leaves': 108, 'min_child_samples': 141, 'min_data_per_groups': 95}. Best is trial 2 with value: 0.9715808170515098.\u001b[0m\n\u001b[32m[I 2023-03-29 15:09:23,134]\u001b[0m Trial 9 finished with value: 0.9609236234458259 and parameters: {'n_estimators': 3000, 'reg_alpha': 1.612062718358246, 'reg_lambda': 0.014759630561362163, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.017, 'max_depth': 100, 'num_leaves': 342, 'min_child_samples': 14, 'min_data_per_groups': 71}. Best is trial 2 with value: 0.9715808170515098.\u001b[0m\n\u001b[32m[I 2023-03-29 15:09:24,769]\u001b[0m Trial 10 finished with value: 0.8940201302545885 and parameters: {'n_estimators': 300, 'reg_alpha': 0.07068392393429204, 'reg_lambda': 0.06402230459100602, 'colsample_bytree': 0.9, 'subsample': 0.4, 'learning_rate': 0.02, 'max_depth': 20, 'num_leaves': 979, 'min_child_samples': 300, 'min_data_per_groups': 8}. Best is trial 2 with value: 0.9715808170515098.\u001b[0m\n\u001b[32m[I 2023-03-29 15:09:55,725]\u001b[0m Trial 11 finished with value: 0.9751332149200711 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.4189313869147432, 'reg_lambda': 0.02496296433852033, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 100, 'num_leaves': 294, 'min_child_samples': 76, 'min_data_per_groups': 50}. Best is trial 11 with value: 0.9751332149200711.\u001b[0m\n\u001b[32m[I 2023-03-29 15:09:57,301]\u001b[0m Trial 12 finished with value: 0.8732978093546477 and parameters: {'n_estimators': 150, 'reg_alpha': 0.25030787428283735, 'reg_lambda': 0.21643203993008256, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 100, 'num_leaves': 297, 'min_child_samples': 82, 'min_data_per_groups': 43}. Best is trial 11 with value: 0.9751332149200711.\u001b[0m\n\u001b[32m[I 2023-03-29 15:10:28,225]\u001b[0m Trial 13 finished with value: 0.9739490822972173 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.28531117305456405, 'reg_lambda': 0.024650475499675698, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 870, 'min_child_samples': 83, 'min_data_per_groups': 22}. Best is trial 11 with value: 0.9751332149200711.\u001b[0m\n\u001b[32m[I 2023-03-29 15:10:59,827]\u001b[0m Trial 14 finished with value: 0.9751332149200711 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.02235368417322128, 'reg_lambda': 0.024631653112627078, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 100, 'num_leaves': 321, 'min_child_samples': 109, 'min_data_per_groups': 22}. Best is trial 11 with value: 0.9751332149200711.\u001b[0m\n\u001b[32m[I 2023-03-29 15:11:27,632]\u001b[0m Trial 15 finished with value: 0.9733570159857904 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.022238305659478142, 'reg_lambda': 0.041411364870933456, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 100, 'num_leaves': 315, 'min_child_samples': 110, 'min_data_per_groups': 23}. Best is trial 11 with value: 0.9751332149200711.\u001b[0m\n\u001b[32m[I 2023-03-29 15:11:29,087]\u001b[0m Trial 16 finished with value: 0.8904677323860273 and parameters: {'n_estimators': 200, 'reg_alpha': 0.013313676102397061, 'reg_lambda': 0.011954281704173689, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 100, 'num_leaves': 385, 'min_child_samples': 170, 'min_data_per_groups': 59}. Best is trial 11 with value: 0.9751332149200711.\u001b[0m\n\u001b[32m[I 2023-03-29 15:11:30,660]\u001b[0m Trial 17 finished with value: 0.8875074008288928 and parameters: {'n_estimators': 150, 'reg_alpha': 0.001189298415738127, 'reg_lambda': 0.0010603843167907925, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.014, 'max_depth': 100, 'num_leaves': 226, 'min_child_samples': 111, 'min_data_per_groups': 23}. Best is trial 11 with value: 0.9751332149200711.\u001b[0m\n\u001b[32m[I 2023-03-29 15:11:32,444]\u001b[0m Trial 18 finished with value: 0.8940201302545885 and parameters: {'n_estimators': 300, 'reg_alpha': 0.04567002072222807, 'reg_lambda': 0.063021513166718, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 100, 'num_leaves': 436, 'min_child_samples': 260, 'min_data_per_groups': 54}. Best is trial 11 with value: 0.9751332149200711.\u001b[0m\n\u001b[32m[I 2023-03-29 15:11:44,270]\u001b[0m Trial 19 finished with value: 0.9484902309058615 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.009491986420092252, 'reg_lambda': 0.007876583044501347, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.017, 'max_depth': 100, 'num_leaves': 7, 'min_child_samples': 44, 'min_data_per_groups': 31}. Best is trial 11 with value: 0.9751332149200711.\u001b[0m\n\u001b[32m[I 2023-03-29 15:12:13,054]\u001b[0m Trial 20 finished with value: 0.9727649496743636 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.16251183997310123, 'reg_lambda': 0.025389781455345557, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 100, 'num_leaves': 191, 'min_child_samples': 105, 'min_data_per_groups': 11}. Best is trial 11 with value: 0.9751332149200711.\u001b[0m\n\u001b[32m[I 2023-03-29 15:12:45,272]\u001b[0m Trial 21 finished with value: 0.9769094138543517 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.11594493008435142, 'reg_lambda': 0.026928166420977374, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 991, 'min_child_samples': 92, 'min_data_per_groups': 19}. Best is trial 21 with value: 0.9769094138543517.\u001b[0m\n\u001b[32m[I 2023-03-29 15:13:16,844]\u001b[0m Trial 22 finished with value: 0.9780935464772055 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.08332067892065656, 'reg_lambda': 0.03260417705199566, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 428, 'min_child_samples': 48, 'min_data_per_groups': 1}. Best is trial 22 with value: 0.9780935464772055.\u001b[0m\n\u001b[32m[I 2023-03-29 15:13:48,863]\u001b[0m Trial 23 finished with value: 0.9775014801657785 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.11422295152995977, 'reg_lambda': 0.09230940462476034, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 563, 'min_child_samples': 40, 'min_data_per_groups': 2}. Best is trial 22 with value: 0.9780935464772055.\u001b[0m\n\u001b[32m[I 2023-03-29 15:14:39,597]\u001b[0m Trial 24 finished with value: 0.9692125518058022 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.09875154095224338, 'reg_lambda': 0.15508894418591354, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 644, 'min_child_samples': 1, 'min_data_per_groups': 1}. Best is trial 22 with value: 0.9780935464772055.\u001b[0m\n\u001b[32m[I 2023-03-29 15:15:13,955]\u001b[0m Trial 25 finished with value: 0.9769094138543517 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.04149947829148246, 'reg_lambda': 0.0716140085632178, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 999, 'min_child_samples': 41, 'min_data_per_groups': 14}. Best is trial 22 with value: 0.9780935464772055.\u001b[0m\n\u001b[32m[I 2023-03-29 15:15:16,496]\u001b[0m Trial 26 finished with value: 0.8727057430432208 and parameters: {'n_estimators': 150, 'reg_alpha': 0.13942648814060954, 'reg_lambda': 0.09939594156381046, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 20, 'num_leaves': 573, 'min_child_samples': 55, 'min_data_per_groups': 1}. Best is trial 22 with value: 0.9780935464772055.\u001b[0m\n\u001b[32m[I 2023-03-29 15:15:23,324]\u001b[0m Trial 27 finished with value: 0.9029011249259917 and parameters: {'n_estimators': 300, 'reg_alpha': 0.06631435836344408, 'reg_lambda': 0.32134956367667883, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.006, 'max_depth': 20, 'num_leaves': 723, 'min_child_samples': 32, 'min_data_per_groups': 16}. Best is trial 22 with value: 0.9780935464772055.\u001b[0m\n\u001b[32m[I 2023-03-29 15:15:26,921]\u001b[0m Trial 28 finished with value: 0.896388395500296 and parameters: {'n_estimators': 200, 'reg_alpha': 0.046501211136170846, 'reg_lambda': 0.04481328229351186, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 20, 'num_leaves': 445, 'min_child_samples': 62, 'min_data_per_groups': 16}. Best is trial 22 with value: 0.9780935464772055.\u001b[0m\n\u001b[32m[I 2023-03-29 15:16:50,778]\u001b[0m Trial 29 finished with value: 0.9745411486086442 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.1746596217571388, 'reg_lambda': 8.773032692155585, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 20, 'num_leaves': 715, 'min_child_samples': 8, 'min_data_per_groups': 30}. Best is trial 22 with value: 0.9780935464772055.\u001b[0m\n\u001b[32m[I 2023-03-29 15:17:00,064]\u001b[0m Trial 30 finished with value: 0.9011249259917111 and parameters: {'n_estimators': 3000, 'reg_alpha': 9.056119381729333, 'reg_lambda': 0.006171363154807769, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.014, 'max_depth': 20, 'num_leaves': 880, 'min_child_samples': 90, 'min_data_per_groups': 7}. Best is trial 22 with value: 0.9780935464772055.\u001b[0m\n\u001b[32m[I 2023-03-29 15:17:31,525]\u001b[0m Trial 31 finished with value: 0.9792776791000593 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.047353474470774884, 'reg_lambda': 0.08826733377969398, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 982, 'min_child_samples': 38, 'min_data_per_groups': 14}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:18:09,159]\u001b[0m Trial 32 finished with value: 0.9792776791000593 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.09754358440053648, 'reg_lambda': 0.1221637187944471, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 939, 'min_child_samples': 33, 'min_data_per_groups': 2}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:19:05,386]\u001b[0m Trial 33 finished with value: 0.9709887507400828 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.06604580470136615, 'reg_lambda': 0.11232151376920349, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 917, 'min_child_samples': 26, 'min_data_per_groups': 1}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:19:41,383]\u001b[0m Trial 34 finished with value: 0.9733570159857904 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.03204636689815183, 'reg_lambda': 0.35994625872142383, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.017, 'max_depth': 10, 'num_leaves': 771, 'min_child_samples': 62, 'min_data_per_groups': 9}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:20:17,047]\u001b[0m Trial 35 finished with value: 0.9775014801657785 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.01629011754550324, 'reg_lambda': 0.2394802753535783, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 917, 'min_child_samples': 37, 'min_data_per_groups': 6}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:20:43,859]\u001b[0m Trial 36 finished with value: 0.9680284191829485 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.08168623932765871, 'reg_lambda': 0.5078809741045199, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 10, 'num_leaves': 822, 'min_child_samples': 128, 'min_data_per_groups': 14}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:22:00,621]\u001b[0m Trial 37 finished with value: 0.9751332149200711 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.03351868547857549, 'reg_lambda': 0.11056103168685909, 'colsample_bytree': 0.9, 'subsample': 0.4, 'learning_rate': 0.006, 'max_depth': 20, 'num_leaves': 570, 'min_child_samples': 20, 'min_data_per_groups': 29}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:22:02,201]\u001b[0m Trial 38 finished with value: 0.8875074008288928 and parameters: {'n_estimators': 200, 'reg_alpha': 0.15836159340669867, 'reg_lambda': 0.6411088319088861, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 712, 'min_child_samples': 163, 'min_data_per_groups': 1}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:22:08,273]\u001b[0m Trial 39 finished with value: 0.9194789816459443 and parameters: {'n_estimators': 300, 'reg_alpha': 0.006439225301356512, 'reg_lambda': 0.17913031432901075, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 20, 'num_leaves': 429, 'min_child_samples': 47, 'min_data_per_groups': 39}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:22:46,168]\u001b[0m Trial 40 finished with value: 0.9727649496743636 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.3740891842491209, 'reg_lambda': 0.11317939174218385, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.017, 'max_depth': 10, 'num_leaves': 820, 'min_child_samples': 65, 'min_data_per_groups': 12}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:23:27,261]\u001b[0m Trial 41 finished with value: 0.9786856127886323 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.02296923659112015, 'reg_lambda': 0.19934620933653252, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 935, 'min_child_samples': 35, 'min_data_per_groups': 6}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:24:04,434]\u001b[0m Trial 42 finished with value: 0.9786856127886323 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.022976717039537523, 'reg_lambda': 0.07911870076932564, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 931, 'min_child_samples': 18, 'min_data_per_groups': 6}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:24:42,070]\u001b[0m Trial 43 finished with value: 0.9769094138543517 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.021385090542963534, 'reg_lambda': 0.17890646251508258, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 936, 'min_child_samples': 17, 'min_data_per_groups': 7}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:26:45,953]\u001b[0m Trial 44 finished with value: 0.9638839550029603 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.012325274410745721, 'reg_lambda': 0.050323376427106596, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 20, 'num_leaves': 865, 'min_child_samples': 3, 'min_data_per_groups': 5}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:27:11,398]\u001b[0m Trial 45 finished with value: 0.9715808170515098 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.047464284635056725, 'reg_lambda': 0.07491433422498928, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 942, 'min_child_samples': 24, 'min_data_per_groups': 19}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:27:13,466]\u001b[0m Trial 46 finished with value: 0.8496151568975725 and parameters: {'n_estimators': 150, 'reg_alpha': 0.02565432171559855, 'reg_lambda': 0.03915713091774267, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.006, 'max_depth': 20, 'num_leaves': 756, 'min_child_samples': 69, 'min_data_per_groups': 11}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:27:39,570]\u001b[0m Trial 47 finished with value: 0.9745411486086442 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.004350427958848398, 'reg_lambda': 0.1407962286895309, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 20, 'num_leaves': 956, 'min_child_samples': 53, 'min_data_per_groups': 77}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:27:45,962]\u001b[0m Trial 48 finished with value: 0.8661930136175252 and parameters: {'n_estimators': 200, 'reg_alpha': 0.017124920725467927, 'reg_lambda': 0.0687879339734196, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 10, 'num_leaves': 883, 'min_child_samples': 29, 'min_data_per_groups': 18}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n\u001b[32m[I 2023-03-29 15:28:28,440]\u001b[0m Trial 49 finished with value: 0.9751332149200711 and parameters: {'n_estimators': 3000, 'reg_alpha': 0.03156921638643959, 'reg_lambda': 0.28910565095544916, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 846, 'min_child_samples': 14, 'min_data_per_groups': 27}. Best is trial 31 with value: 0.9792776791000593.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Number of finished trials: 50\nBest trial: {'n_estimators': 3000, 'reg_alpha': 0.047353474470774884, 'reg_lambda': 0.08826733377969398, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.017, 'max_depth': 20, 'num_leaves': 982, 'min_child_samples': 38, 'min_data_per_groups': 14}\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\nmodel = LGBMClassifier(**params_lgbm)\nmodel.fit(X_train, y_train, early_stopping_rounds=50, eval_set=[(X_test, y_test)], verbose=False)   \ny_pred = model.predict(X_test)\nprint(f\"Accuracy: {round(accuracy_score(y_pred, y_test), 2)}\")\nprint(\"=\"*60)\nprint(f\"Recall: {round(recall_score(y_pred,y_test),2)}\")\nprint(\"=\"*60)\nprint(f\"Precision: {round(precision_score(y_pred,y_test), 2)}\")\nprint(\"=\"*60)\nprint(f\"F1: {round(f1_score(y_pred,y_test), 2)}\")\nprint(\"=\"*60)\nprint(f\"Auc: {round(roc_auc_score(y_pred,y_test), 2)}\")\nprint(\"=\"*60)\nCR = classification_report(y_test, y_pred)\nCM = confusion_matrix(y_test, y_pred)\nprint(f\"Classification Report:\\n {CR}\")\nprint(\"=\"*60)\nprint(f\"Confusion Matrix: {CM}\")\nprint(\"=\"*60)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T15:29:55.234130Z","iopub.execute_input":"2023-03-29T15:29:55.234483Z","iopub.status.idle":"2023-03-29T15:30:30.795203Z","shell.execute_reply.started":"2023-03-29T15:29:55.234458Z","shell.execute_reply":"2023-03-29T15:30:30.793734Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: min_data_per_groups\nAccuracy: 0.98\n============================================================\nRecall: 0.96\n============================================================\nPrecision: 0.9\n============================================================\nF1: 0.93\n============================================================\nAuc: 0.97\n============================================================\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99      1405\n           1       0.96      0.90      0.93       284\n\n    accuracy                           0.98      1689\n   macro avg       0.97      0.95      0.96      1689\nweighted avg       0.98      0.98      0.98      1689\n\n============================================================\nConfusion Matrix: [[1395   10]\n [  27  257]]\n============================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ncnt = 1\n# split()  method generate indices to split data into training and test set.\nfor train_index, test_index in kf.split(X, y):\n    print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n    cnt+=1\n\nscore = cross_val_score(ensemble.RandomForestClassifier(random_state= 42), X, y, cv= kf, scoring=\"accuracy\")\nprint(f'Scores for each fold are: {score}')\nprint(f'Average score: {\"{:.2f}\".format(score.mean())}')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T14:25:22.217277Z","iopub.execute_input":"2023-03-29T14:25:22.217618Z","iopub.status.idle":"2023-03-29T14:25:25.245841Z","shell.execute_reply.started":"2023-03-29T14:25:22.217584Z","shell.execute_reply":"2023-03-29T14:25:25.244738Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Fold:1, Train set: 4504, Test set:1126\nFold:2, Train set: 4504, Test set:1126\nFold:3, Train set: 4504, Test set:1126\nFold:4, Train set: 4504, Test set:1126\nFold:5, Train set: 4504, Test set:1126\nScores for each fold are: [0.97158082 0.95648313 0.96358792 0.97158082 0.97069272]\nAverage score: 0.97\n","output_type":"stream"}]},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n\ncatboost_model = CatBoostClassifier(verbose=False, random_state=42).fit(X_train, y_train)\ny_pred = catboost_model.predict(X_test)\n\nprint(f\"Accuracy: {round(accuracy_score(y_pred, y_test), 2)}\")\nprint(\"=\"*60)\nprint(f\"Recall: {round(recall_score(y_pred,y_test),2)}\")\nprint(\"=\"*60)\nprint(f\"Precision: {round(precision_score(y_pred,y_test), 2)}\")\nprint(\"=\"*60)\nprint(f\"F1: {round(f1_score(y_pred,y_test), 2)}\")\nprint(\"=\"*60)\nprint(f\"Auc: {round(roc_auc_score(y_pred,y_test), 2)}\")\nprint(\"=\"*60)\nCR = classification_report(y_test, y_pred)\nCM = confusion_matrix(y_test, y_pred)\nprint(f\"Classification Report:\\n {CR}\")\nprint(\"=\"*60)\nprint(f\"Confusion Matrix: {CM}\")\nprint(\"=\"*60)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T15:05:33.048396Z","iopub.execute_input":"2023-03-29T15:05:33.048761Z","iopub.status.idle":"2023-03-29T15:05:35.359259Z","shell.execute_reply.started":"2023-03-29T15:05:33.048734Z","shell.execute_reply":"2023-03-29T15:05:35.358221Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Accuracy: 0.96\n============================================================\nRecall: 0.93\n============================================================\nPrecision: 0.82\n============================================================\nF1: 0.87\n============================================================\nAuc: 0.95\n============================================================\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98      1414\n           1       0.93      0.82      0.87       275\n\n    accuracy                           0.96      1689\n   macro avg       0.95      0.90      0.92      1689\nweighted avg       0.96      0.96      0.96      1689\n\n============================================================\nConfusion Matrix: [[1396   18]\n [  49  226]]\n============================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}